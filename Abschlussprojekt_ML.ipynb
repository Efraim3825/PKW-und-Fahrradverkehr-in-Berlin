{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551b1161-9c40-4cf5-891d-a02504a8a65b",
   "metadata": {},
   "source": [
    "## Initialisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2008f57f-00a6-4efe-8bbe-ed09744526dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine#, text, MetaData, Table, Column, String\n",
    "from geopy.geocoders import Nominatim\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import holidays\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c121c0ac-b350-464e-a782-0c717a27d45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_password = '' # Benutze hier dein MySQL- Passwort\n",
    "engine = create_engine('mysql+mysqlconnector://root:' + sql_password + '@localhost:3306/verkehrsprojekt')\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb7205b-3300-4e88-a416-13cbf48fb5e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819163fc-b402-4b4d-8e7e-7771a78a9986",
   "metadata": {},
   "source": [
    "#### Dataframe erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d783fd-a3b9-43b9-966b-d39a54cbd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkw- Spalte\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT  \n",
    "    timestamp, Durchschnitt\n",
    "FROM \n",
    "    pkw_daten\n",
    "\"\"\"\n",
    "df = pd.read_sql(query,engine)\n",
    "df = df.rename(columns = {'Durchschnitt':'Anzahl PKW'})\n",
    "df  = df.set_index('timestamp')\n",
    "pkw_spalte = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf81ae9-80b3-4bfa-a4db-232ee6ad6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fahrrad- Spalte\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT  \n",
    "    timestamp, Durchschnitt\n",
    "FROM \n",
    "    fahrraddaten\n",
    "\"\"\"\n",
    "df = pd.read_sql(query,engine)\n",
    "df = df.rename(columns = {'Durchschnitt':'Anzahl Fahrräder'})\n",
    "df  = df.set_index('timestamp')\n",
    "fahrrad_spalte = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2432dc-669c-4603-8bce-95de74925915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe für Machine learning erstellen\n",
    "\n",
    "df = pd.read_csv('Bezirke_Durchschnitt.csv', decimal = '.' )\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['precipitation (mm)'] = df['rain (mm)'] + 10*df['snowfall (cm)']\n",
    "df = df.drop(columns = ['rain (mm)', 'snowfall (cm)'])\n",
    "df['dayofweek'] = df['time'].dt.dayofweek\n",
    "df['month'] = df['time'].dt.month\n",
    "df['hour'] = df['time'].dt.hour \n",
    "berlin_holidays = holidays.Germany(state = 'BE')\n",
    "df['is_holiday'] = df['time'].apply(lambda x: berlin_holidays.get(x, None))\n",
    "df['is_holiday'] = df['is_holiday'].apply(lambda x: 1 if isinstance(x, str) else 0) # Es ist komisch, dass ich das in zwei Schritten machen muss. Aber die isin- methode hat komische Ergebnisse produziert\n",
    "#df['is_holiday'] = ((df['is_holiday'] == 1) | (df['dayofweek'] == 6)).astype(int) # Auch Sonntage sollen als Holiday gewertet werden\n",
    "df = df.rename(columns = {'time':'timestamp'})\n",
    "df = df.set_index('timestamp')\n",
    "df = pd.concat([df,pkw_spalte,fahrrad_spalte], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5b0a3b-7361-40c4-b29c-e564422be0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN filtern\n",
    "df = df[~df['Anzahl PKW'].isna()]\n",
    "df = df[~df['Anzahl Fahrräder'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b00abf6-b73c-4422-9175-be943b74048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aureißer ausschließen\n",
    "problem_tage = [\n",
    "'2018-04-25',\n",
    "'2019-07-28',\n",
    "'2019-10-20',\n",
    "'2021-12-13',\n",
    "'2023-01-30',\n",
    "'2023-05-15',\n",
    "]\n",
    "problem_tage = pd.to_datetime(problem_tage)\n",
    "filt = df.index.normalize().isin(problem_tage)\n",
    "df = df[~filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8157631-c559-410d-add5-eb755a6711d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unscaled = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c29d8e4-1594-425d-9979-f2b4728b13b9",
   "metadata": {},
   "source": [
    "#### Betrachte den Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4bf0e131-44da-4376-b8a3-aa3954e2984b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>relative_humidity_2m (%)</th>\n",
       "      <th>cloud_cover (%)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>Anzahl PKW</th>\n",
       "      <th>Anzahl Fahrräder</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-01-01 00:00:00</th>\n",
       "      <td>11.066667</td>\n",
       "      <td>71.666667</td>\n",
       "      <td>61.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183.208</td>\n",
       "      <td>6.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 01:00:00</th>\n",
       "      <td>11.141667</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>357.316</td>\n",
       "      <td>10.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 02:00:00</th>\n",
       "      <td>11.591667</td>\n",
       "      <td>64.500000</td>\n",
       "      <td>92.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>359.928</td>\n",
       "      <td>15.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 03:00:00</th>\n",
       "      <td>11.825000</td>\n",
       "      <td>62.083333</td>\n",
       "      <td>95.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>284.856</td>\n",
       "      <td>13.269231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01 04:00:00</th>\n",
       "      <td>11.641667</td>\n",
       "      <td>63.416667</td>\n",
       "      <td>93.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>225.944</td>\n",
       "      <td>8.115385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temperature_2m (°C)  relative_humidity_2m (%)  \\\n",
       "timestamp                                                            \n",
       "2018-01-01 00:00:00            11.066667                 71.666667   \n",
       "2018-01-01 01:00:00            11.141667                 70.000000   \n",
       "2018-01-01 02:00:00            11.591667                 64.500000   \n",
       "2018-01-01 03:00:00            11.825000                 62.083333   \n",
       "2018-01-01 04:00:00            11.641667                 63.416667   \n",
       "\n",
       "                     cloud_cover (%)  precipitation (mm)  dayofweek  month  \\\n",
       "timestamp                                                                    \n",
       "2018-01-01 00:00:00        61.333333            0.000000          0      1   \n",
       "2018-01-01 01:00:00        77.250000            0.016667          0      1   \n",
       "2018-01-01 02:00:00        92.416667            0.000000          0      1   \n",
       "2018-01-01 03:00:00        95.916667            0.000000          0      1   \n",
       "2018-01-01 04:00:00        93.916667            0.000000          0      1   \n",
       "\n",
       "                     hour  is_holiday  Anzahl PKW  Anzahl Fahrräder  \n",
       "timestamp                                                            \n",
       "2018-01-01 00:00:00     0           1     183.208          6.538462  \n",
       "2018-01-01 01:00:00     1           1     357.316         10.730769  \n",
       "2018-01-01 02:00:00     2           1     359.928         15.153846  \n",
       "2018-01-01 03:00:00     3           1     284.856         13.269231  \n",
       "2018-01-01 04:00:00     4           1     225.944          8.115385  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "95ff9552-550c-4f87-bda6-32d2be2724a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df, plot_kws={\"s\": 0.05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ad33ddf3-85f8-4ac1-9482-50fa895672e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>relative_humidity_2m (%)</th>\n",
       "      <th>cloud_cover (%)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>Anzahl PKW</th>\n",
       "      <th>Anzahl Fahrräder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "      <td>51886.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.993283</td>\n",
       "      <td>73.602441</td>\n",
       "      <td>65.410857</td>\n",
       "      <td>0.090869</td>\n",
       "      <td>3.007170</td>\n",
       "      <td>6.528447</td>\n",
       "      <td>11.512219</td>\n",
       "      <td>0.027715</td>\n",
       "      <td>440.466693</td>\n",
       "      <td>90.083151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.250195</td>\n",
       "      <td>18.149008</td>\n",
       "      <td>37.809799</td>\n",
       "      <td>0.407510</td>\n",
       "      <td>1.997962</td>\n",
       "      <td>3.454696</td>\n",
       "      <td>6.920103</td>\n",
       "      <td>0.164155</td>\n",
       "      <td>247.726517</td>\n",
       "      <td>79.933258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-14.375000</td>\n",
       "      <td>14.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.661597</td>\n",
       "      <td>0.115385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.591667</td>\n",
       "      <td>60.833333</td>\n",
       "      <td>29.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>187.627605</td>\n",
       "      <td>19.213942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.375000</td>\n",
       "      <td>77.666667</td>\n",
       "      <td>84.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>475.621792</td>\n",
       "      <td>70.423077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.181250</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>99.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>657.805121</td>\n",
       "      <td>141.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37.358333</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>13.691667</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>923.629482</td>\n",
       "      <td>423.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       temperature_2m (°C)  relative_humidity_2m (%)  cloud_cover (%)  \\\n",
       "count         51886.000000              51886.000000     51886.000000   \n",
       "mean             10.993283                 73.602441        65.410857   \n",
       "std               8.250195                 18.149008        37.809799   \n",
       "min             -14.375000                 14.583333         0.000000   \n",
       "25%               4.591667                 60.833333        29.666667   \n",
       "50%              10.375000                 77.666667        84.333333   \n",
       "75%              17.181250                 89.166667        99.750000   \n",
       "max              37.358333                100.000000       100.000000   \n",
       "\n",
       "       precipitation (mm)     dayofweek         month          hour  \\\n",
       "count        51886.000000  51886.000000  51886.000000  51886.000000   \n",
       "mean             0.090869      3.007170      6.528447     11.512219   \n",
       "std              0.407510      1.997962      3.454696      6.920103   \n",
       "min              0.000000      0.000000      1.000000      0.000000   \n",
       "25%              0.000000      1.000000      4.000000      6.000000   \n",
       "50%              0.000000      3.000000      7.000000     12.000000   \n",
       "75%              0.000000      5.000000     10.000000     18.000000   \n",
       "max             13.691667      6.000000     12.000000     23.000000   \n",
       "\n",
       "         is_holiday    Anzahl PKW  Anzahl Fahrräder  \n",
       "count  51886.000000  51886.000000      51886.000000  \n",
       "mean       0.027715    440.466693         90.083151  \n",
       "std        0.164155    247.726517         79.933258  \n",
       "min        0.000000     20.661597          0.115385  \n",
       "25%        0.000000    187.627605         19.213942  \n",
       "50%        0.000000    475.621792         70.423077  \n",
       "75%        0.000000    657.805121        141.133333  \n",
       "max        1.000000    923.629482        423.500000  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bc8f4943-67e5-412c-bc4d-976a5a8950c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.regplot(x = df['relative_humidity_2m (%)'], y = df['Anzahl Fahrräder'], order = 1, scatter_kws={\"s\": 0.01})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60de66-4e70-4d4f-a160-b23b44b1eb1a",
   "metadata": {},
   "source": [
    "#### Normalisiere den Dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1bc41d4-53c6-4f1d-986a-2df4644780e1",
   "metadata": {},
   "source": [
    "Temperatur sieht grob Gauß- verteilt aus. Niederschlag hat sher kleine Varianz. Deswegen Standard-Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7f2a0786-eb59-46d6-a636-92aea240b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[['precipitation (mm)']] = scaler.fit_transform(df[['precipitation (mm)']])\n",
    "df[['temperature_2m (°C)']] = scaler.fit_transform(df[['temperature_2m (°C)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "07b70bed-b46f-40be-8c8a-0184ca3e7ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "df[['relative_humidity_2m (%)','cloud_cover (%)']] = scaler.fit_transform(df[['relative_humidity_2m (%)','cloud_cover (%)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "74af9362-64fe-43ed-aded-79f36c536cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Temp\\ipykernel_2500\\3043990704.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Anzahl PKW'] , df['Anzahl Fahrräder'] = df['Anzahl PKW'] / ( df['Anzahl PKW'] + df['Anzahl Fahrräder'] ) , df['Anzahl Fahrräder'] / ( df['Anzahl PKW'] + df['Anzahl Fahrräder'] )\n"
     ]
    }
   ],
   "source": [
    "#Stelle Anzahl PKW, Fahrräder anteilig an ihrere Gesamtsumme dar\n",
    "df['Anzahl PKW'] , df['Anzahl Fahrräder'] = df['Anzahl PKW'] / ( df['Anzahl PKW'] + df['Anzahl Fahrräder'] ) , df['Anzahl Fahrräder'] / ( df['Anzahl PKW'] + df['Anzahl Fahrräder'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "20884c3f-06aa-4644-aa9b-c5127f5c51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['temperature_2m (°C)'].hist(bins = 200, density = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "67983018-8676-46eb-92b9-332d5db7d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['precipitation (mm)'][df['precipitation (mm)'] >= 0].hist(bins = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ad3d666-4e77-43aa-92fb-89f370583bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['snowfall (cm)'][df['snowfall (cm)'] >= 0].hist(bins = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb3e936-a043-435c-884f-9e2dfc509c1e",
   "metadata": {},
   "source": [
    "#### Automatisierte Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95cce672-aa9f-426c-953a-d76c23897dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "223c1b1a-6c9b-4221-b22e-ed9cf86a4308",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scaler = StandardScaler()\n",
    "m_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a668076-92ed-47a9-affb-80e12882114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling_methods = ['keine', 'minmax', 'standard']\n",
    "scaling_methods = ['keine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31b0a00e-0872-4373-b078-cf9a6c60dc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "wetter_features = df_unscaled[['temperature_2m (°C)', 'relative_humidity_2m (%)', 'cloud_cover (%)', 'precipitation (mm)']]\n",
    "zeit_features = df_unscaled[['dayofweek', 'month', 'hour']]\n",
    "zeit_features = pd.concat( [ zeit_features.drop('dayofweek', axis = 1), pd.get_dummies(zeit_features['dayofweek'], prefix = 'dow', dtype = int) ], axis = 1)\n",
    "zeit_features = pd.concat( [ zeit_features.drop('month', axis = 1), pd.get_dummies(zeit_features['month'], prefix = 'month', dtype = int) ], axis = 1)\n",
    "zeit_features = pd.concat( [ zeit_features.drop('hour', axis = 1), pd.get_dummies(zeit_features['hour'], prefix = 'hour', dtype = int) ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16d3f116-5a19-4df8-aa14-de51de6dd966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Untersuchtes Fahrzeug: PKW oder Fahrrad? Aktiviere/Deaktiviere die jeweileige Zeile\n",
    "fahrzeug = 'PKW'\n",
    "#fahrzeug = 'Fahrräder'\n",
    "\n",
    "column_names = ['temperature_2m (°C)', 'relative_humidity_2m (%)', 'cloud_cover (%)', 'precipitation (mm)', 'Anzahl ' + fahrzeug]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79c01491-0e52-4c49-92ca-a971c53faff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welche Features sollen berücksichtigt werden?\n",
    "use_weather_features = True\n",
    "use_time_features = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2e93f8-4f94-4b52-ad9e-bba4ea0301e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hier kennst du dich auf die entscheidenden konzentrieren, um die runtime zu erhöhen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b3acc6b2-b19d-4927-a813-898455bea783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verwendeter Algorithmus: SVR\n",
      "Verwendete Features: ['Wetter', 'Zeit']\n",
      "Betrachtetes Fahrzeug: PKW\n",
      "['keine', 'keine', 'keine', 'keine', 'keine']\n",
      "bester R^2: 0.16531284833973203\n",
      "schlechtester R^2: 0.16531284833973203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################################### Original\n",
    "best_r2 = - float(\"inf\")\n",
    "worst_r2 = float(\"inf\")\n",
    "method_collection = {name: None for name in column_names}\n",
    "for method_temp in scaling_methods:\n",
    "    for method_hum in scaling_methods:\n",
    "        for method_cloud in scaling_methods:\n",
    "            for method_prec in scaling_methods:\n",
    "                for method_num in scaling_methods:\n",
    "\n",
    "                    # Erstelle das df, je nachdem, welche Features du benutzt\n",
    "                    df = df_unscaled.drop(columns = df_unscaled.columns)\n",
    "                    if use_weather_features:\n",
    "                        df[wetter_features.columns] = wetter_features\n",
    "                    if use_time_features:\n",
    "                        df[zeit_features.columns] = zeit_features\n",
    "                    df[[f'Anzahl {fahrzeug}']] = df_unscaled[[f'Anzahl {fahrzeug}']]\n",
    "                    \n",
    "                    method_collection['temperature_2m (°C)'] = method_temp\n",
    "                    method_collection['relative_humidity_2m (%)'] = method_hum\n",
    "                    method_collection['cloud_cover (%)'] = method_cloud\n",
    "                    method_collection['precipitation (mm)'] = method_prec\n",
    "                    method_collection[f'Anzahl {fahrzeug}'] = method_num\n",
    "\n",
    "                    if use_weather_features:\n",
    "                        for name in column_names:\n",
    "                            if method_collection[name] == 'keine':\n",
    "                                pass\n",
    "                            elif method_collection[name] == 'minmax':\n",
    "                                df[[name]] = m_scaler.fit_transform(df[[name]])\n",
    "                            elif method_collection[name] == 'standard':\n",
    "                                df[[name]] = s_scaler.fit_transform(df[[name]])\n",
    "\n",
    "                    X = df.drop(columns = [f'Anzahl {fahrzeug}'])\n",
    "                    y = df[[f'Anzahl {fahrzeug}']]\n",
    "                    \n",
    "                    split_filt = ( y.index < '2023-01-01 00:00:00' )\n",
    "                    X_train, y_train = X[split_filt], y[split_filt]\n",
    "                    X_test, y_test = X[~split_filt], y[~split_filt]\n",
    "\n",
    "                    model = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_pred = model.predict(X_test)\n",
    "                    mse = mean_squared_error(y_test, y_pred)\n",
    "                    sd = np.sqrt(mse)\n",
    "                    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "                    worst_r2 = min(r2,worst_r2)\n",
    "                    if r2 > best_r2:\n",
    "                        best_method_collection = method_collection\n",
    "                        best_r2 = r2\n",
    "\n",
    "\n",
    "Verwendete_Features = ['Wetter' if use_weather_features else ''] + ['Zeit' if use_time_features else '']\n",
    "print(f\"Verwendeter Algorithmus: SVR\")\n",
    "print(f\"Verwendete Features: {Verwendete_Features}\")\n",
    "print(f\"Betrachtetes Fahrzeug: {fahrzeug}\")\n",
    "if use_weather_features:\n",
    "    print([best_method_collection[key]for key in best_method_collection])\n",
    "print(f\"bester R^2: {best_r2}\")\n",
    "print(f\"schlechtester R^2: {worst_r2}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "858009cb-bbcb-484c-ac68-f5f2b927c49b",
   "metadata": {},
   "source": [
    "Untersuchen SVR mit verschiedenen Parametern."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c0aaace-e695-4e0e-8b9f-65669ff6b812",
   "metadata": {},
   "source": [
    "Das musst du am Anfang des Tages machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d463293d-ba76-4219-9178-93eb3e17722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['linear', 0.1, 0.001, 0.001]\n",
      "0.6785160748454775\n"
     ]
    }
   ],
   "source": [
    "print(best_parameter_collection)\n",
    "print(best_r2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6748b31-a22b-49a3-a8ed-fa437b02fe8b",
   "metadata": {},
   "source": [
    "['linear', 0.1, 0.001, 0.001]\n",
    "0.6785160748454775"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd04233d-530d-47bd-b321-1b0c53386a12",
   "metadata": {},
   "source": [
    "tested: kernel = linear, C = 10, epsilon = 0.001, gamma = 1\n",
    "R^2 = 0.7758535318644834\n",
    "\n",
    "hängt nur von C ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9752682c-bce1-4c3e-a7a3-5b6dfb6fcaaf",
   "metadata": {},
   "source": [
    "ähnlich gut mit C = 100, kernel linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1ffc2-adf6-49f3-a723-e9f1791894a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested: kernel = rbf, C = 0.1, epsilon = 0.001, gamma = 0.001\n",
      "R^2 = 0.0052600135098281875\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tested: kernel = rbf, C = 0.1, epsilon = 0.001, gamma = 0.01\n",
      "R^2 = 0.0052600135098281875\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "### speziell SVR\n",
    "scaling_methods = ['keine','minmax','standard']\n",
    "kernel_types = ['rbf']#['sigmoid', 'poly','linear', 'rbf']\n",
    "C_values = [0.1, 1, 10, 100]\n",
    "epsilon_values = [0.001, 0.01, 0.1, 0.5, 1]\n",
    "gamma_values = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "best_r2 = - float(\"inf\")\n",
    "worst_r2 = float(\"inf\")\n",
    "method_collection = {name: None for name in column_names}\n",
    "\n",
    "for kernel in kernel_types:\n",
    "    for C in C_values:\n",
    "        for epsilon in epsilon_values:\n",
    "            for gamma in gamma_values:\n",
    "                for method_temp in ['keine']:\n",
    "                    for method_hum in ['minmax']:\n",
    "                        for method_cloud in ['minmax']:\n",
    "                            for method_prec in ['keine']:\n",
    "                                for method_num in ['keine']:\n",
    "                \n",
    "                                    # Erstelle das df, je nachdem, welche Features du benutzt\n",
    "                                    df = df_unscaled.drop(columns = df_unscaled.columns)\n",
    "                                    if use_weather_features:\n",
    "                                        df[wetter_features.columns] = wetter_features\n",
    "                                    if use_time_features:\n",
    "                                        df[zeit_features.columns] = zeit_features\n",
    "                                    df[[f'Anzahl {fahrzeug}']] = df_unscaled[[f'Anzahl {fahrzeug}']]\n",
    "                                    \n",
    "                                    method_collection['temperature_2m (°C)'] = method_temp\n",
    "                                    method_collection['relative_humidity_2m (%)'] = method_hum\n",
    "                                    method_collection['cloud_cover (%)'] = method_cloud\n",
    "                                    method_collection['precipitation (mm)'] = method_prec\n",
    "                                    method_collection[f'Anzahl {fahrzeug}'] = method_num\n",
    "                \n",
    "                                    if use_weather_features:\n",
    "                                        for name in column_names:\n",
    "                                            if method_collection[name] == 'keine':\n",
    "                                                pass\n",
    "                                            elif method_collection[name] == 'minmax':\n",
    "                                                df[[name]] = m_scaler.fit_transform(df[[name]])\n",
    "                                            elif method_collection[name] == 'standard':\n",
    "                                                df[[name]] = s_scaler.fit_transform(df[[name]])\n",
    "                \n",
    "                                    X = df.drop(columns = [f'Anzahl {fahrzeug}'])\n",
    "                                    y = df[[f'Anzahl {fahrzeug}']]\n",
    "                                    \n",
    "                                    split_filt = ( y.index < '2023-01-01 00:00:00' )\n",
    "                                    X_train, y_train = X[split_filt], y[split_filt]\n",
    "                                    X_test, y_test = X[~split_filt], y[~split_filt]\n",
    "                \n",
    "                                    model = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
    "                                    model.fit(X_train, y_train)\n",
    "                                    y_pred = model.predict(X_test)\n",
    "                                    mse = mean_squared_error(y_test, y_pred)\n",
    "                                    sd = np.sqrt(mse)\n",
    "                                    r2 = r2_score(y_test, y_pred)\n",
    "                \n",
    "                                    worst_r2 = min(r2,worst_r2)\n",
    "                                    if r2 > best_r2:\n",
    "                                        best_parameter_collection = [kernel,C,epsilon,gamma]\n",
    "                                        best_r2 = r2\n",
    "                                    print(f\"tested: kernel = {kernel}, C = {C}, epsilon = {epsilon}, gamma = {gamma}\")\n",
    "                                    print(f\"R^2 = {r2}\")\n",
    "                                    print(\"\")\n",
    "                                    print(\"\")\n",
    "\n",
    "\n",
    "Verwendete_Features = ['Wetter' if use_weather_features else ''] + ['Zeit' if use_time_features else '']\n",
    "print(f\"Verwendeter Algorithmus: SVR\")\n",
    "print(f\"Verwendete Features: {Verwendete_Features}\")\n",
    "print(f\"Betrachtetes Fahrzeug: {fahrzeug}\")\n",
    "if use_weather_features:\n",
    "    print([best_method_collection[key]for key in best_method_collection])\n",
    "print(f\"bester R^2: {best_r2}\")\n",
    "print(f\"schlechtester R^2: {worst_r2}\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e917b6e-176e-4a0a-b210-ba661dffeed9",
   "metadata": {},
   "source": [
    "Verwendeter Algorithmus: LinReg\n",
    "Verwendete Features: ['Wetter', 'Zeit']\n",
    "Betrachtetes Fahrzeug: PKW\n",
    "['standard', 'standard', 'standard', 'standard', 'standard']\n",
    "bester R^2: 0.8132837991198782\n",
    "schlechtester R^2: 0.812517419418667\n",
    "\n",
    "Verwendeter Algorithmus: LinReg\n",
    "Verwendete Features: ['Wetter', '']\n",
    "Betrachtetes Fahrzeug: PKW\n",
    "['standard', 'standard', 'standard', 'standard', 'standard']\n",
    "bester R^2: 0.16487253193571283\n",
    "schlechtester R^2: 0.16487253193570284\n",
    "\n",
    "Verwendeter Algorithmus: LinReg\n",
    "Verwendete Features: ['', 'Zeit']\n",
    "Betrachtetes Fahrzeug: PKW\n",
    "bester R^2: 0.8138988763608256\n",
    "schlechtester R^2: 0.8138988763608256\n",
    "\n",
    "Verwendeter Algorithmus: LinReg\n",
    "Verwendete Features: ['Wetter', 'Zeit']\n",
    "Betrachtetes Fahrzeug: Fahrräder\n",
    "['standard', 'standard', 'standard', 'standard', 'standard']\n",
    "bester R^2: 0.7564069409041096\n",
    "schlechtester R^2: 0.7556611392859166\n",
    "\n",
    "Verwendeter Algorithmus: LinReg\n",
    "Verwendete Features: ['Wetter', '']\n",
    "Betrachtetes Fahrzeug: Fahrräder\n",
    "['standard', 'standard', 'standard', 'standard', 'standard']\n",
    "bester R^2: 0.3570793783948395\n",
    "schlechtester R^2: 0.3570793783948286\n",
    "\n",
    "Verwendeter Algorithmus: LinReg\n",
    "Verwendete Features: ['', 'Zeit']\n",
    "Betrachtetes Fahrzeug: Fahrräder\n",
    "bester R^2: 0.7151671727324795\n",
    "schlechtester R^2: 0.7151671727324795\n",
    "\n",
    "Verwendeter Algorithmus: Gradient Boost\n",
    "Verwendete Features: ['Wetter', 'Zeit']\n",
    "Betrachtetes Fahrzeug: PKW\n",
    "['standard', 'standard', 'standard', 'standard', 'standard']\n",
    "bester R^2: 0.8704272979258182\n",
    "schlechtester R^2: 0.870424046843463\n",
    "\n",
    "Verwendeter Algorithmus: Gradient Boost\n",
    "Verwendete Features: ['', 'Zeit']\n",
    "Betrachtetes Fahrzeug: PKW\n",
    "bester R^2: 0.874692558315692\n",
    "schlechtester R^2: 0.874692558315692\n",
    "\n",
    "Verwendeter Algorithmus: Gradient Boost\n",
    "Verwendete Features: ['Wetter', '']\n",
    "Betrachtetes Fahrzeug: PKW\n",
    "['keine', 'keine', 'keine', 'standard', 'minmax']\n",
    "bester R^2: 0.19239239716142753\n",
    "schlechtester R^2: 0.1923923971614273\n",
    "\n",
    "Verwendeter Algorithmus: Gradient Boost\n",
    "Verwendete Features: ['Wetter', 'Zeit']\n",
    "Betrachtetes Fahrzeug: Fahrräder\n",
    "['standard', 'standard', 'standard', 'standard', 'standard']\n",
    "bester R^2: 0.7926220023973779\n",
    "schlechtester R^2: 0.7926110945929256\n",
    "\n",
    "Verwendeter Algorithmus: Gradient Boost\n",
    "Verwendete Features: ['', 'Zeit']\n",
    "Betrachtetes Fahrzeug: Fahrräder\n",
    "bester R^2: 0.7077973252935614\n",
    "schlechtester R^2: 0.7077973252935614\n",
    "\n",
    "Verwendeter Algorithmus: Gradient Boost\n",
    "Verwendete Features: ['Wetter', '']\n",
    "Betrachtetes Fahrzeug: Fahrräder\n",
    "['standard', 'standard', 'standard', 'standard', 'standard']\n",
    "bester R^2: 0.38325582664532865\n",
    "schlechtester R^2: 0.3832267680195913"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ebc44-ca28-4593-8448-3d2d4c8c40fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Verschiedene Algorithmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1fea277-faab-4796-ab5d-17810bd899c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat( [ df.drop('dayofweek', axis = 1), pd.get_dummies(df['dayofweek'], prefix = 'dow', dtype = int) ], axis = 1)\n",
    "df = pd.concat( [ df.drop('month', axis = 1), pd.get_dummies(df['month'], prefix = 'month', dtype = int) ], axis = 1)\n",
    "df = pd.concat( [ df.drop('hour', axis = 1), pd.get_dummies(df['hour'], prefix = 'hour', dtype = int) ], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c12d1504-505c-481b-b4db-0464b12dab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[['temperature_2m (°C)','relative_humidity_2m (%)','rain (mm)','snowfall (cm)','cloud_cover (%)']]\n",
    "#X = df.drop(columns = ['temperature_2m (°C)','relative_humidity_2m (%)','rain (mm)','snowfall (cm)','cloud_cover (%)', 'Anzahl PKW', 'Anzahl Fahrräder'])\n",
    "X = df.drop(columns = ['Anzahl PKW', 'Anzahl Fahrräder'])\n",
    "y = df[['Anzahl PKW']]\n",
    "#y = df[['Anzahl Fahrräder']]\n",
    "#y = df[['Anzahl PKW','Anzahl Fahrräder']]\n",
    "\n",
    "split_filt = ( y.index < '2023-01-01 00:00:00' )\n",
    "X_train, y_train = X[split_filt], y[split_filt]\n",
    "X_test, y_test = X[~split_filt], y[~split_filt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dafb79-ed5b-441a-b5fe-f001b25dca0b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Lineare Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d2da27e-fa83-4c7a-be9e-b37818519824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation: 0.04785495221567448\n",
      "\n",
      "R^2 Score: 0.6808519360456639\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    sd = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Ergebnisse\n",
    "    print(f\"Standard Deviation: {sd}\")\n",
    "    print(\"\")\n",
    "    print(f\"R^2 Score: {r2}\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    #print(\"\")\n",
    "    #print(\"Koeffizienten:\", model.coef_)\n",
    "    #print(\"Achsenabschnitt (Intercept):\", model.intercept_)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ca396e1-3460-4f63-8936-7c86caea535e",
   "metadata": {},
   "source": [
    "PKW \n",
    "\n",
    "R^2 Score\n",
    "Feature und Label skaliert: 0.6808519360456639\n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:\n",
    "\n",
    "Standard deviation:\n",
    "Feature und Label skaliert: 0.04785495221567448\n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fcbb9fb-7218-4d7a-96af-685be3c6842d",
   "metadata": {},
   "source": [
    "Fahrrad\n",
    "\n",
    "R^2 Score\n",
    "Feature und Label skaliert: \n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:\n",
    "\n",
    "Standard deviation:\n",
    "Feature und Label skaliert: \n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ffb902-2c97-4486-9489-60e66b862b90",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b78bac-b542-4c52-9d52-5a815f6e221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "09b84358-667c-4aec-bdb4-a0de526e795f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardabweichung: 0.04031627131767241\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    knn = KNeighborsRegressor(n_neighbors=20)  # n_neighbors ist die Anzahl der Nachbarn\n",
    "\n",
    "    # Modell trainieren\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen treffen\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Performance bewerten\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    sd = np.sqrt(mse)\n",
    "    print(f\"Standardabweichung: {sd}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "608b66e1-0a3b-4e7c-a3d3-e0872a416783",
   "metadata": {},
   "source": [
    "PKW\n",
    "\n",
    "Standard deviation:\n",
    "Feature und Label skaliert: 0.04031627131767241\n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9bdc23-51af-4688-9a4a-c3f3487cc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    param_grid = {'n_neighbors': range(1, 21)}\n",
    "    grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9928bf-78de-47ad-83c2-a984b962aea9",
   "metadata": {},
   "source": [
    "##### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3127949e-36e7-4106-80fb-7877332ba7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beste Parameter: 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "620410a1-8f40-4808-8514-2f895ec8ee41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardabweichung: 51.58040659092073\n",
      "R^2 Score: 0.6245722261523179\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "if False:\n",
    "    begin = time()\n",
    "    rf = RandomForestRegressor(n_estimators=200, random_state=42, max_depth = 10, min_samples_leaf = 1, min_samples_split = 10)\n",
    "    \n",
    "    # Modell trainieren\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen treffen\n",
    "    y_pred = rf.predict(X_test)\n",
    "    \n",
    "    # Performance evaluieren\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    sd = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    end = time()\n",
    "    print(f\"Standardabweichung: {sd}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b726456c-0507-4593-b137-8eea54e61c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],  # Anzahl der Bäume\n",
    "        'max_depth': [None, 10, 20],    # Maximale Tiefe\n",
    "        'min_samples_split': [2, 5, 10],  # Mindestanzahl von Stichproben für Split\n",
    "        'min_samples_leaf': [1, 2, 4]    # Mindestanzahl von Stichproben in einem Blatt\n",
    "    }\n",
    "    \n",
    "    grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    print(f\"Beste Parameter: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd6390-95fd-4c27-baf0-d8cacdb07cfa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "65be3152-93c6-4c7c-803f-10fe33bc4337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230.98116445541382\n",
      "Standard Deviation: 42.39785361252609\n",
      "R^2 Score: 0.746344304730622\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    begin = time()\n",
    "    # SVR-Modell initialisieren (mit RBF-Kernel)\n",
    "    svr = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "    \n",
    "    # Modell trainieren\n",
    "    svr.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen treffen\n",
    "    y_pred = svr.predict(X_test)\n",
    "    \n",
    "    # Performance evaluieren\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    sd = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    end = time()\n",
    "    print(end-begin)\n",
    "    print(f\"Standard Deviation: {sd}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e38bf960-dad2-4d8b-9be5-6c00182f4ba6",
   "metadata": {},
   "source": [
    "R^2 Score\n",
    "Feature und Label skaliert: 0.561610557963625\n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:\n",
    "\n",
    "Standard deviation:\n",
    "Feature und Label skaliert: 0.056086820745629026\n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7817f8a6-4f69-4662-b956-f6c9e84ef8f3",
   "metadata": {},
   "source": [
    "andere Methode\n",
    "https://www.youtube.com/watch?v=3CC4N4z3GJc\n",
    "https://www.youtube.com/watch?v=2xudPOBz-vs\n",
    "https://www.youtube.com/watch?v=jxuNLH5dXCs\n",
    "https://www.youtube.com/watch?v=StWY5QWMXCw\n",
    "https://www.youtube.com/watch?v=Q81RR3yKn30\n",
    "https://www.youtube.com/watch?v=NGf0voTMlcs\n",
    "https://www.youtube.com/watch?v=en2bmeB4QUo\n",
    "https://en.wikipedia.org/wiki/Kernel_density_estimation\n",
    "https://onlinelibrary.wiley.com/doi/full/10.1155/2018/1012647\n",
    "gammaverteilung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdc3261-8d06-44e9-bf6f-11efdf1061d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d623e7d2-585f-4a1a-a8fd-0e472b185d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:668: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)  # TODO: Is this still required?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.39844012260437\n",
      "Standardabweichung: 45.505475372749416\n",
      "R^2 Score: 0.7077973252935614\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    begin = time()\n",
    "    gbr = GradientBoostingRegressor(\n",
    "        n_estimators=100,     # Anzahl der Bäume\n",
    "        learning_rate=0.1,    # Lernrate (Schrittgröße)\n",
    "        max_depth=3,          # Maximale Tiefe der Bäume\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Modell trainieren\n",
    "    gbr.fit(X_train, y_train)\n",
    "    \n",
    "    # Vorhersagen treffen\n",
    "    y_pred = gbr.predict(X_test)\n",
    "    \n",
    "    # Performance evaluieren\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    sd = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    end = time()\n",
    "    print(end-begin)\n",
    "    print(f\"Standardabweichung: {sd}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a220bbe4-42f8-438c-8515-a4e19abfb24b",
   "metadata": {},
   "source": [
    "R^2 Score\n",
    "Feature und Label skaliert: 0.6922184219607871\n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:\n",
    "\n",
    "Standard deviation:\n",
    "Feature und Label skaliert: 0.046995047273826154\n",
    "Feature Skaliert:\n",
    "Label skaliert:\n",
    "unskaliert:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e1d39f-1a50-4bbb-a443-d0f9ef3cee9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Anderes Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2539d5e3-7da6-49c4-8a59-797db5547a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Efi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\genmod\\families\\links.py:13: FutureWarning: The logit link alias is deprecated. Use Logit instead. The logit link alias will be removed after the 0.15.0 release.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "PatsyError",
     "evalue": "Number of rows mismatch between data argument and y (740 versus 51886)\n    y ~ X\n    ^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[257], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfamilies\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logit\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenmod\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfamilies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Binomial\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43msmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my ~ X\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlink\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Ergebnisse anzeigen\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\base\\model.py:203\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:  \u001b[38;5;66;03m# with patsy it's drop or raise. let's raise.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 203\u001b[0m tmp \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_formula_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m ((endog, exog), missing_idx, design_info) \u001b[38;5;241m=\u001b[39m tmp\n\u001b[0;32m    206\u001b[0m max_endog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_formula_max_endog\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\statsmodels\\formula\\formulatools.py:63\u001b[0m, in \u001b[0;36mhandle_formula_data\u001b[1;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_util\u001b[38;5;241m.\u001b[39m_is_using_pandas(Y, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 63\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mdmatrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataframe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m         result \u001b[38;5;241m=\u001b[39m dmatrices(formula, Y, depth, return_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataframe\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     67\u001b[0m                            NA_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\patsy\\highlevel.py:319\u001b[0m, in \u001b[0;36mdmatrices\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Construct two design matrices given a formula_like and data.\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \n\u001b[0;32m    311\u001b[0m \u001b[38;5;124;03mThis function is identical to :func:`dmatrix`, except that it requires\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;124;03mSee :func:`dmatrix` for details.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    318\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m EvalEnvironment\u001b[38;5;241m.\u001b[39mcapture(eval_env, reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 319\u001b[0m (lhs, rhs) \u001b[38;5;241m=\u001b[39m \u001b[43m_do_highlevel_design\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lhs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PatsyError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel is missing required outcome variables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\patsy\\highlevel.py:168\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    164\u001b[0m design_infos \u001b[38;5;241m=\u001b[39m _try_incr_builders(\n\u001b[0;32m    165\u001b[0m     formula_like, data_iter_maker, eval_env, NA_action\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m design_infos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_design_matrices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesign_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# No builders, but maybe we can still get matrices\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formula_like, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\patsy\\build.py:959\u001b[0m, in \u001b[0;36mbuild_design_matrices\u001b[1;34m(design_infos, data, NA_action, return_type, dtype)\u001b[0m\n\u001b[0;32m    957\u001b[0m name \u001b[38;5;241m=\u001b[39m factor_info\u001b[38;5;241m.\u001b[39mfactor\u001b[38;5;241m.\u001b[39mname()\n\u001b[0;32m    958\u001b[0m origin \u001b[38;5;241m=\u001b[39m factor_info\u001b[38;5;241m.\u001b[39mfactor\u001b[38;5;241m.\u001b[39morigin\n\u001b[1;32m--> 959\u001b[0m \u001b[43mrows_checker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (pandas\u001b[38;5;241m.\u001b[39mSeries, pandas\u001b[38;5;241m.\u001b[39mDataFrame)):\n\u001b[0;32m    961\u001b[0m     index_checker\u001b[38;5;241m.\u001b[39mcheck(value\u001b[38;5;241m.\u001b[39mindex, name, origin)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\patsy\\build.py:858\u001b[0m, in \u001b[0;36m_CheckMatch.check\u001b[1;34m(self, seen_value, desc, origin)\u001b[0m\n\u001b[0;32m    855\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m versus \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue, seen_value)\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# XX FIXME: this is a case where having discontiguous Origins\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;66;03m# would be useful...\u001b[39;00m\n\u001b[1;32m--> 858\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m PatsyError(msg, origin)\n",
      "\u001b[1;31mPatsyError\u001b[0m: Number of rows mismatch between data argument and y (740 versus 51886)\n    y ~ X\n    ^"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.genmod.families.links import logit\n",
    "from statsmodels.genmod.families import Binomial\n",
    "\n",
    "model = smf.glm('y ~ X', data=data, family=Binomial(link=logit()))\n",
    "results = model.fit()\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(results.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
